{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-11 14:33:10.422194: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-11 14:33:10.439571: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1754890390.460679 1808799 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1754890390.467538 1808799 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-08-11 14:33:10.490087: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from helper_code import *\n",
    "import random\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "import json\n",
    "import glob\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n",
      "--xla_gpu_cuda_data_dir=/home/shjee/miniconda3/envs/tf-gpu/nvvm/libdevice\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "print(os.environ.get(\"XLA_FLAGS\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''random seed 설정'''\n",
    "def seed_everything(seed=42):\n",
    "    \"\"\"\n",
    "    TensorFlow 환경에서 재현 가능한 결과를 위해 모든 시드와 환경변수를 설정합니다.\n",
    "    \n",
    "    **사용 전 주의사항:**\n",
    "      - TensorFlow 임포트 전에 아래와 같이 determinism 관련 환경변수를 설정해야 합니다.\n",
    "            os.environ[\"TF_DETERMINISTIC_OPS\"] = \"1\"\n",
    "            os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    \"\"\"\n",
    "    # 환경변수 재설정 (필요 시)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    os.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = \"0\"  # OneDNN 최적화 비활성화 (재현성을 위해)\n",
    "\n",
    "    # 파이썬, numpy, TensorFlow 시드 설정\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "\n",
    "# 랜덤 시드 기록 함수\n",
    "def save_random_seed(seed, filepath):\n",
    "    with open(filepath, 'wb') as f:\n",
    "        pickle.dump(seed, f)\n",
    "\n",
    "# 랜덤 시드 로드 함수\n",
    "def load_random_seed(filepath):\n",
    "    with open(filepath, 'rb') as f:\n",
    "        seed = pickle.load(f)\n",
    "    return seed\n",
    "\n",
    "# 랜덤 시드 설정 및 저장\n",
    "def set_random_seed(seed_save_path, use_saved_seed=False):\n",
    "\n",
    "    # 새로운 랜덤 시드를 생성하고 저장\n",
    "    random_seed = random.randint(0, 100000)\n",
    "    random.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    tf.random.set_seed(random_seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(random_seed)\n",
    "    save_random_seed(random_seed, seed_save_path)\n",
    "    print(f\"Generated new seed: {random_seed}\")\n",
    "\n",
    "\n",
    "# 랜덤 시드 설정 함수 (저장된 시드 로드)\n",
    "def set_random_seed_from_file(seed_save_path):\n",
    "    # 저장된 시드를 로드하여 사용\n",
    "    random_seed = load_random_seed(seed_save_path)\n",
    "    print(f\"Using saved seed: {random_seed}\")\n",
    "    \n",
    "        # 랜덤 시드 설정\n",
    "    # Python 내장 random 시드 설정\n",
    "    random.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    tf.random.set_seed(random_seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(random_seed)\n",
    "\n",
    "\n",
    "    return random_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed_path = r'C:\\Users\\medai01\\Desktop\\ecg\\random_seed.pkl'\n",
    "# set_random_seed_from_file(random_seed_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Challenge lead sets. These variables are not required. You can change or remove them.\n",
    "twelve_leads = ('I', 'II', 'III', 'aVR', 'aVL', 'aVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6')\n",
    "six_leads = ('I', 'II', 'III', 'aVR', 'aVL', 'aVF')\n",
    "four_leads = ('I', 'II', 'III', 'V2')\n",
    "three_leads = ('I', 'II', 'V2')\n",
    "two_leads = ('I', 'II')\n",
    "lead_sets = (twelve_leads, six_leads, four_leads, three_leads, two_leads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processed_ecg_data(base_path):\n",
    "    hea_file_paths = []\n",
    "    mat_file_paths = []\n",
    "\n",
    "    for subdir, dirs, _ in os.walk(base_path):\n",
    "        for dir in dirs:\n",
    "            g_dirs_path = os.path.join(subdir, dir, \"g*\")\n",
    "            g_dirs = glob.glob(g_dirs_path)\n",
    "\n",
    "            for g_dir in g_dirs:\n",
    "                dir_hea_files = glob.glob(os.path.join(g_dir, \"*.hea\"))\n",
    "                dir_mat_files = glob.glob(os.path.join(g_dir, \"*.mat\"))\n",
    "\n",
    "                # .hea 파일과 .mat 파일이 모두 존재하는 경우에만 리스트에 추가\n",
    "                for hea_file in dir_hea_files:\n",
    "                    base_file_name = os.path.splitext(hea_file)[0]\n",
    "                    mat_file = base_file_name + \".mat\"\n",
    "                    if mat_file in dir_mat_files:\n",
    "                        hea_file_paths.append(hea_file)\n",
    "                        mat_file_paths.append(mat_file)\n",
    "\n",
    "    return hea_file_paths, mat_file_paths\n",
    "\n",
    "\n",
    "model_path = '/home/shjee/projects/ecg1d/model'\n",
    "base_path = '/home/shjee/projects/ecg1d/physionet.org/training'\n",
    "_ ,  X_files = processed_ecg_data(base_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/shjee/projects/ecg1d/physionet.org/training/chapman_shaoxing/g4/JS03210.mat', '/home/shjee/projects/ecg1d/physionet.org/training/chapman_shaoxing/g4/JS03713.mat', '/home/shjee/projects/ecg1d/physionet.org/training/chapman_shaoxing/g4/JS03831.mat', '/home/shjee/projects/ecg1d/physionet.org/training/chapman_shaoxing/g4/JS03583.mat', '/home/shjee/projects/ecg1d/physionet.org/training/chapman_shaoxing/g4/JS04023.mat', '/home/shjee/projects/ecg1d/physionet.org/training/chapman_shaoxing/g4/JS03735.mat', '/home/shjee/projects/ecg1d/physionet.org/training/chapman_shaoxing/g4/JS04135.mat', '/home/shjee/projects/ecg1d/physionet.org/training/chapman_shaoxing/g4/JS03621.mat', '/home/shjee/projects/ecg1d/physionet.org/training/chapman_shaoxing/g4/JS03527.mat', '/home/shjee/projects/ecg1d/physionet.org/training/chapman_shaoxing/g4/JS03202.mat']\n"
     ]
    }
   ],
   "source": [
    "print(X_files[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_train_dict(train_dict, save_path):\n",
    "    \"\"\"\n",
    "    train_dict 데이터를 파일로 저장하는 함수.\n",
    "\n",
    "    \"\"\"\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "    # JSON으로 저장할 데이터\n",
    "    json_data = {\n",
    "        \"header_files\": train_dict[\"header_files\"],\n",
    "        \"recording_files\": train_dict[\"recording_files\"],\n",
    "        \"classes\": train_dict[\"classes\"]\n",
    "    }\n",
    "\n",
    "    # JSON 저장\n",
    "    json_file = os.path.join(save_path, \"metadata.json\")\n",
    "    with open(json_file, \"w\") as f:\n",
    "        json.dump(json_data, f, indent=4)\n",
    "    \n",
    "    # NPY로 저장할 데이터\n",
    "    npy_keys = [\"train_labels\", \"test_labels\", \"val_labels\", \"train_files\", \"test_files\", \"val_files\"]\n",
    "    \n",
    "    for key in npy_keys:\n",
    "        npy_file = os.path.join(save_path, f\"{key}.npy\")\n",
    "        np.save(npy_file, train_dict[key])\n",
    "\n",
    "    print(f\"Train dictionary saved at {save_path}\")\n",
    "\n",
    "def load_train_dict(load_path):\n",
    "    \"\"\"\n",
    "    저장된 데이터를 불러와 train_dict 형태로 변환하는 함수.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(load_path):\n",
    "        raise FileNotFoundError(f\"{load_path} does not exist.\")\n",
    "\n",
    "    # JSON 데이터 로드\n",
    "    json_file = os.path.join(load_path, \"metadata.json\")\n",
    "    with open(json_file, \"r\") as f:\n",
    "        json_data = json.load(f)\n",
    "\n",
    "    # NPY 데이터 로드\n",
    "    npy_keys = [\"train_labels\", \"test_labels\", \"val_labels\", \"train_files\", \"test_files\", \"val_files\"]\n",
    "    npy_data = {key: np.load(os.path.join(load_path, f\"{key}.npy\"), allow_pickle=True) for key in npy_keys}\n",
    "\n",
    "    # 복원된 train_dict\n",
    "    train_dict = {**json_data, **npy_data}\n",
    "\n",
    "    print(f\"Train dictionary loaded from {load_path}\")\n",
    "    return train_dict\n",
    "\n",
    "\n",
    "# # 저장\n",
    "# save_train_dict(train_dict, \"train_dict_storage\")\n",
    "\n",
    "# 불러오기\n",
    "# train_dict = load_train_dict(\"train_dict_storage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tensorboard --logdir=logs/fit --port=6006'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 256\n",
    "epochs = 60\n",
    "signal_len = 5000\n",
    "model_directory = model_path\n",
    "\n",
    "'''tensorboard --logdir=logs/fit --port=6006'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "총 0개의 헤더가 누락되었습니다.\n"
     ]
    }
   ],
   "source": [
    "def check_missing_headers(X_files):\n",
    "    missing_headers = []\n",
    "\n",
    "    for mat_path in X_files:\n",
    "        hea_path = os.path.splitext(mat_path)[0] + \".hea\"\n",
    "        if not os.path.exists(hea_path):\n",
    "            print(f\"[헤더 없음] {hea_path}\")\n",
    "            missing_headers.append(hea_path)\n",
    "\n",
    "    print(f\"\\n총 {len(missing_headers)}개의 헤더가 누락되었습니다.\")\n",
    "    \n",
    "    return missing_headers\n",
    "\n",
    "\n",
    "missing = check_missing_headers(X_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_start\n",
      "85376\n",
      "=== Train ===\n",
      "NSR: 22866\n",
      "SB: 14931\n",
      "TAb: 9163\n",
      "STach: 7054\n",
      "PVC/VPB: 6507\n",
      "AFL: 6342\n",
      "LAD: 6064\n",
      "AF: 4142\n",
      "TInv: 3075\n",
      "CRBBB/RBBB: 2814\n",
      "IAVB: 2793\n",
      "SA: 2706\n",
      "PAC/SVPB: 2554\n",
      "LAnFB: 1726\n",
      "QAb: 1644\n",
      "LQT: 1511\n",
      "IRBBB: 1474\n",
      "NSIVCB: 1390\n",
      "LQRSV: 1260\n",
      "CLBBB/LBBB: 1167\n",
      "RAD: 989\n",
      "PR: 907\n",
      "PRWP: 482\n",
      "\n",
      "=== Validation ===\n",
      "NSR: 2858\n",
      "SB: 1867\n",
      "TAb: 1145\n",
      "STach: 882\n",
      "PVC/VPB: 818\n",
      "AFL: 792\n",
      "LAD: 758\n",
      "AF: 517\n",
      "TInv: 384\n",
      "CRBBB/RBBB: 351\n",
      "IAVB: 349\n",
      "SA: 338\n",
      "PAC/SVPB: 319\n",
      "LAnFB: 216\n",
      "QAb: 205\n",
      "LQT: 189\n",
      "IRBBB: 184\n",
      "NSIVCB: 174\n",
      "LQRSV: 158\n",
      "CLBBB/LBBB: 145\n",
      "RAD: 124\n",
      "PR: 114\n",
      "PRWP: 60\n",
      "\n",
      "=== Test ===\n",
      "NSR: 2858\n",
      "SB: 1866\n",
      "TAb: 1146\n",
      "STach: 882\n",
      "PVC/VPB: 808\n",
      "AFL: 793\n",
      "LAD: 758\n",
      "AF: 518\n",
      "TInv: 384\n",
      "CRBBB/RBBB: 352\n",
      "IAVB: 349\n",
      "SA: 338\n",
      "PAC/SVPB: 319\n",
      "LAnFB: 216\n",
      "QAb: 205\n",
      "LQT: 189\n",
      "IRBBB: 184\n",
      "NSIVCB: 174\n",
      "LQRSV: 157\n",
      "CLBBB/LBBB: 145\n",
      "RAD: 124\n",
      "PR: 113\n",
      "PRWP: 60\n",
      "\n",
      "[INFO] 클래스별 개수 분포를 label_distribution.xlsx로 저장했습니다.\n",
      "load_end\n"
     ]
    }
   ],
   "source": [
    "from team_code import load_data, load_data_2, train_model_2\n",
    "\n",
    "X_train_all, y_train_all, X_val_all, y_val_all, X_test_all, y_test_all, abbreviation_sorted = load_data_2(X_files)\n",
    "# X_train_all, y_train_all = load_data(train_files)\n",
    "# X_val_all, y_val_all  = load_data(val_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('abbreviation_sorted.txt', 'w', encoding='utf-8') as f:\n",
    "    for abbr in abbreviation_sorted:\n",
    "        f.write(abbr + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1754890486.461658 1808799 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43184 MB memory:  -> device: 0, name: NVIDIA L40S, pci bus id: 0000:b8:00.0, compute capability: 8.9\n",
      "I0000 00:00:1754890486.462277 1808799 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 881 MB memory:  -> device: 1, name: NVIDIA L40S, pci bus id: 0000:c8:00.0, compute capability: 8.9\n",
      "Preprocessing with DWT + bandpass + standardization: 100%|██████████| 61707/61707 [02:00<00:00, 511.38it/s]\n",
      "Preprocessing with DWT + bandpass + standardization: 100%|██████████| 7718/7718 [00:14<00:00, 517.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtering complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1754890624.905420 1810046 gpu_backend_lib.cc:579] Can't find libdevice directory ${CUDA_DIR}/nvvm/libdevice. This may result in compilation or runtime failures, if the program we try to run uses routines from libdevice.\n",
      "Searched for CUDA in the following directories:\n",
      "  /home/shjee/miniconda3/envs/tf-gpu/nvvm/libdevice\n",
      "  ipykernel_launcher.runfiles/cuda_nvcc\n",
      "  ipykern/cuda_nvcc\n",
      "  \n",
      "  /usr/local/cuda\n",
      "  /home/shjee/miniconda3/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/python/platform/../../../nvidia/cuda_nvcc\n",
      "  /home/shjee/miniconda3/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/python/platform/../../../../nvidia/cuda_nvcc\n",
      "  /home/shjee/miniconda3/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/python/platform/../../cuda\n",
      "  .\n",
      "You can choose the search directory by setting xla_gpu_cuda_data_dir in HloModule's DebugOptions.  For most apps, setting the environment variable XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda will work.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Start...\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1754890644.000834 1809626 service.cc:148] XLA service 0x7380b4003240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1754890644.000896 1809626 service.cc:156]   StreamExecutor device (0): NVIDIA L40S, Compute Capability 8.9\n",
      "I0000 00:00:1754890644.000905 1809626 service.cc:156]   StreamExecutor device (1): NVIDIA L40S, Compute Capability 8.9\n",
      "2025-08-11 14:37:24.539458: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1754890649.348344 1809626 cuda_dnn.cc:529] Loaded cuDNN version 91100\n",
      "2025-08-11 14:38:12.751423: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'input_convert_reduce_fusion_19', 8 bytes spill stores, 8 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_convert_reduce_fusion_6', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  1/241\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:25:45\u001b[0m 66s/step - dynamic_f1: 0.1094 - loss: 2.9213"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1754890692.983964 1809626 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dynamic_f1: 0.1419 - loss: 2.4728"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-11 14:38:29.612156: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1767', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "2025-08-11 14:38:29.750293: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1767_0', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: saving model to /home/shjee/projects/ecg1d/model/DWT_model_4_leads_lr0.0001_e01_valf10.17.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 90ms/step - dynamic_f1: 0.1420 - loss: 2.4714 - val_dynamic_f1: 0.1690 - val_loss: 2.4274 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 2/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dynamic_f1: 0.2124 - loss: 1.7095\n",
      "Epoch 2: saving model to /home/shjee/projects/ecg1d/model/DWT_model_4_leads_lr0.0001_e02_valf10.23.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 68ms/step - dynamic_f1: 0.2124 - loss: 1.7094 - val_dynamic_f1: 0.2288 - val_loss: 2.0055 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 3/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dynamic_f1: 0.2424 - loss: 1.6397\n",
      "Epoch 3: saving model to /home/shjee/projects/ecg1d/model/DWT_model_4_leads_lr0.0001_e03_valf10.29.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - dynamic_f1: 0.2424 - loss: 1.6397 - val_dynamic_f1: 0.2910 - val_loss: 1.6271 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 4/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - dynamic_f1: 0.2648 - loss: 1.6043\n",
      "Epoch 4: saving model to /home/shjee/projects/ecg1d/model/DWT_model_4_leads_lr0.0001_e04_valf10.32.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 67ms/step - dynamic_f1: 0.2648 - loss: 1.6043 - val_dynamic_f1: 0.3210 - val_loss: 1.5953 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 5/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dynamic_f1: 0.2867 - loss: 1.5837\n",
      "Epoch 5: saving model to /home/shjee/projects/ecg1d/model/DWT_model_4_leads_lr0.0001_e05_valf10.31.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - dynamic_f1: 0.2868 - loss: 1.5836 - val_dynamic_f1: 0.3147 - val_loss: 1.5599 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 6/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dynamic_f1: 0.3043 - loss: 1.5600\n",
      "Epoch 6: saving model to /home/shjee/projects/ecg1d/model/DWT_model_4_leads_lr0.0001_e06_valf10.30.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 68ms/step - dynamic_f1: 0.3043 - loss: 1.5599 - val_dynamic_f1: 0.2992 - val_loss: 1.6245 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 7/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - dynamic_f1: 0.3180 - loss: 1.5497\n",
      "Epoch 7: saving model to /home/shjee/projects/ecg1d/model/DWT_model_4_leads_lr0.0001_e07_valf10.29.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 67ms/step - dynamic_f1: 0.3181 - loss: 1.5497 - val_dynamic_f1: 0.2930 - val_loss: 1.7685 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 8/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dynamic_f1: 0.3243 - loss: 1.5511\n",
      "Epoch 8: saving model to /home/shjee/projects/ecg1d/model/DWT_model_4_leads_lr0.0001_e08_valf10.33.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - dynamic_f1: 0.3244 - loss: 1.5511 - val_dynamic_f1: 0.3270 - val_loss: 1.5619 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 9/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dynamic_f1: 0.3347 - loss: 1.5297\n",
      "Epoch 9: saving model to /home/shjee/projects/ecg1d/model/DWT_model_4_leads_lr0.0001_e09_valf10.33.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 68ms/step - dynamic_f1: 0.3347 - loss: 1.5297 - val_dynamic_f1: 0.3306 - val_loss: 1.5326 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 10/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dynamic_f1: 0.3442 - loss: 1.5101\n",
      "Epoch 10: saving model to /home/shjee/projects/ecg1d/model/DWT_model_4_leads_lr0.0001_e10_valf10.35.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 68ms/step - dynamic_f1: 0.3442 - loss: 1.5101 - val_dynamic_f1: 0.3504 - val_loss: 1.4889 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.0005000000237487257.\n",
      "Epoch 11/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dynamic_f1: 0.3596 - loss: 1.4790\n",
      "Epoch 11: saving model to /home/shjee/projects/ecg1d/model/DWT_model_4_leads_lr0.0001_e11_valf10.37.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 68ms/step - dynamic_f1: 0.3596 - loss: 1.4790 - val_dynamic_f1: 0.3728 - val_loss: 1.4626 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.0005000000237487257.\n",
      "Epoch 12/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dynamic_f1: 0.3701 - loss: 1.4628\n",
      "Epoch 12: saving model to /home/shjee/projects/ecg1d/model/DWT_model_4_leads_lr0.0001_e12_valf10.37.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 68ms/step - dynamic_f1: 0.3702 - loss: 1.4628 - val_dynamic_f1: 0.3750 - val_loss: 1.4406 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.0005000000237487257.\n",
      "Epoch 13/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dynamic_f1: 0.3775 - loss: 1.4515\n",
      "Epoch 13: saving model to /home/shjee/projects/ecg1d/model/DWT_model_4_leads_lr0.0001_e13_valf10.39.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - dynamic_f1: 0.3776 - loss: 1.4515 - val_dynamic_f1: 0.3853 - val_loss: 1.4540 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.0005000000237487257.\n",
      "Epoch 14/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dynamic_f1: 0.3857 - loss: 1.4440\n",
      "Epoch 14: saving model to /home/shjee/projects/ecg1d/model/DWT_model_4_leads_lr0.0001_e14_valf10.40.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - dynamic_f1: 0.3858 - loss: 1.4440 - val_dynamic_f1: 0.3951 - val_loss: 1.4156 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0005000000237487257.\n",
      "Epoch 15/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dynamic_f1: 0.3904 - loss: 1.4362\n",
      "Epoch 15: saving model to /home/shjee/projects/ecg1d/model/DWT_model_4_leads_lr0.0001_e15_valf10.40.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - dynamic_f1: 0.3905 - loss: 1.4362 - val_dynamic_f1: 0.4021 - val_loss: 1.4288 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.0005000000237487257.\n",
      "Epoch 16/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dynamic_f1: 0.3975 - loss: 1.4295\n",
      "Epoch 16: saving model to /home/shjee/projects/ecg1d/model/DWT_model_4_leads_lr0.0001_e16_valf10.40.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 68ms/step - dynamic_f1: 0.3975 - loss: 1.4295 - val_dynamic_f1: 0.4030 - val_loss: 1.4328 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0005000000237487257.\n",
      "Epoch 17/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - dynamic_f1: 0.4040 - loss: 1.4250\n",
      "Epoch 17: saving model to /home/shjee/projects/ecg1d/model/DWT_model_4_leads_lr0.0001_e17_valf10.40.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 67ms/step - dynamic_f1: 0.4040 - loss: 1.4250 - val_dynamic_f1: 0.3999 - val_loss: 1.4466 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.0005000000237487257.\n",
      "Epoch 18/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dynamic_f1: 0.4088 - loss: 1.4194\n",
      "Epoch 18: saving model to /home/shjee/projects/ecg1d/model/DWT_model_4_leads_lr0.0001_e18_valf10.39.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 68ms/step - dynamic_f1: 0.4089 - loss: 1.4194 - val_dynamic_f1: 0.3948 - val_loss: 1.4328 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.0005000000237487257.\n",
      "Epoch 19/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dynamic_f1: 0.4113 - loss: 1.4179\n",
      "Epoch 19: saving model to /home/shjee/projects/ecg1d/model/DWT_model_4_leads_lr0.0001_e19_valf10.38.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 68ms/step - dynamic_f1: 0.4113 - loss: 1.4179 - val_dynamic_f1: 0.3832 - val_loss: 1.4611 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.0005000000237487257.\n",
      "Epoch 20/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dynamic_f1: 0.4160 - loss: 1.4136\n",
      "Epoch 20: saving model to /home/shjee/projects/ecg1d/model/DWT_model_4_leads_lr0.0001_e20_valf10.40.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - dynamic_f1: 0.4160 - loss: 1.4136 - val_dynamic_f1: 0.3972 - val_loss: 1.4714 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0002500000118743628.\n",
      "Epoch 21/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dynamic_f1: 0.4278 - loss: 1.3977\n",
      "Epoch 21: saving model to /home/shjee/projects/ecg1d/model/DWT_model_4_leads_lr0.0001_e21_valf10.40.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - dynamic_f1: 0.4278 - loss: 1.3977 - val_dynamic_f1: 0.3960 - val_loss: 1.4413 - learning_rate: 2.5000e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.0002500000118743628.\n",
      "Epoch 22/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dynamic_f1: 0.4384 - loss: 1.3845\n",
      "Epoch 22: saving model to /home/shjee/projects/ecg1d/model/DWT_model_4_leads_lr0.0001_e22_valf10.41.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 68ms/step - dynamic_f1: 0.4385 - loss: 1.3845 - val_dynamic_f1: 0.4091 - val_loss: 1.4369 - learning_rate: 2.5000e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.0002500000118743628.\n",
      "Epoch 23/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dynamic_f1: 0.4411 - loss: 1.3823\n",
      "Epoch 23: saving model to /home/shjee/projects/ecg1d/model/DWT_model_4_leads_lr0.0001_e23_valf10.41.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 68ms/step - dynamic_f1: 0.4411 - loss: 1.3823 - val_dynamic_f1: 0.4053 - val_loss: 1.4305 - learning_rate: 2.5000e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0002500000118743628.\n",
      "Epoch 24/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dynamic_f1: 0.4498 - loss: 1.3707\n",
      "Epoch 24: saving model to /home/shjee/projects/ecg1d/model/DWT_model_4_leads_lr0.0001_e24_valf10.41.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 68ms/step - dynamic_f1: 0.4498 - loss: 1.3707 - val_dynamic_f1: 0.4147 - val_loss: 1.4467 - learning_rate: 2.5000e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.0002500000118743628.\n",
      "Epoch 25/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - dynamic_f1: 0.4562 - loss: 1.3641\n",
      "Epoch 25: saving model to /home/shjee/projects/ecg1d/model/DWT_model_4_leads_lr0.0001_e25_valf10.40.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 70ms/step - dynamic_f1: 0.4563 - loss: 1.3641 - val_dynamic_f1: 0.4007 - val_loss: 1.4795 - learning_rate: 2.5000e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0002500000118743628.\n",
      "Epoch 26/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dynamic_f1: 0.4596 - loss: 1.3573\n",
      "Epoch 26: saving model to /home/shjee/projects/ecg1d/model/DWT_model_4_leads_lr0.0001_e26_valf10.41.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - dynamic_f1: 0.4597 - loss: 1.3573 - val_dynamic_f1: 0.4068 - val_loss: 1.4614 - learning_rate: 2.5000e-04\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.0002500000118743628.\n",
      "Epoch 27/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dynamic_f1: 0.4663 - loss: 1.3521\n",
      "Epoch 27: saving model to /home/shjee/projects/ecg1d/model/DWT_model_4_leads_lr0.0001_e27_valf10.42.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - dynamic_f1: 0.4664 - loss: 1.3521 - val_dynamic_f1: 0.4245 - val_loss: 1.4231 - learning_rate: 2.5000e-04\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.0002500000118743628.\n",
      "Epoch 28/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dynamic_f1: 0.4727 - loss: 1.3473\n",
      "Epoch 28: saving model to /home/shjee/projects/ecg1d/model/DWT_model_4_leads_lr0.0001_e28_valf10.42.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - dynamic_f1: 0.4727 - loss: 1.3473 - val_dynamic_f1: 0.4161 - val_loss: 1.4435 - learning_rate: 2.5000e-04\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.0002500000118743628.\n",
      "Epoch 29/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dynamic_f1: 0.4744 - loss: 1.3455\n",
      "Epoch 29: saving model to /home/shjee/projects/ecg1d/model/DWT_model_4_leads_lr0.0001_e29_valf10.42.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - dynamic_f1: 0.4744 - loss: 1.3455 - val_dynamic_f1: 0.4198 - val_loss: 1.4370 - learning_rate: 2.5000e-04\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0002500000118743628.\n",
      "Epoch 30/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dynamic_f1: 0.4783 - loss: 1.3414\n",
      "Epoch 30: saving model to /home/shjee/projects/ecg1d/model/DWT_model_4_leads_lr0.0001_e30_valf10.41.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - dynamic_f1: 0.4783 - loss: 1.3414 - val_dynamic_f1: 0.4128 - val_loss: 1.4319 - learning_rate: 2.5000e-04\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.0001250000059371814.\n",
      "Epoch 31/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dynamic_f1: 0.4852 - loss: 1.3324\n",
      "Epoch 31: saving model to /home/shjee/projects/ecg1d/model/DWT_model_4_leads_lr0.0001_e31_valf10.42.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 68ms/step - dynamic_f1: 0.4852 - loss: 1.3324 - val_dynamic_f1: 0.4245 - val_loss: 1.4382 - learning_rate: 1.2500e-04\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.0001250000059371814.\n",
      "Epoch 32/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dynamic_f1: 0.4934 - loss: 1.3241\n",
      "Epoch 32: saving model to /home/shjee/projects/ecg1d/model/DWT_model_4_leads_lr0.0001_e32_valf10.42.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 70ms/step - dynamic_f1: 0.4934 - loss: 1.3241 - val_dynamic_f1: 0.4217 - val_loss: 1.4409 - learning_rate: 1.2500e-04\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.0001250000059371814.\n",
      "Epoch 33/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - dynamic_f1: 0.4976 - loss: 1.3185\n",
      "Epoch 33: saving model to /home/shjee/projects/ecg1d/model/DWT_model_4_leads_lr0.0001_e33_valf10.42.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 68ms/step - dynamic_f1: 0.4977 - loss: 1.3185 - val_dynamic_f1: 0.4171 - val_loss: 1.4321 - learning_rate: 1.2500e-04\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.0001250000059371814.\n",
      "Epoch 34/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dynamic_f1: 0.5011 - loss: 1.3145\n",
      "Epoch 34: saving model to /home/shjee/projects/ecg1d/model/DWT_model_4_leads_lr0.0001_e34_valf10.42.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 68ms/step - dynamic_f1: 0.5011 - loss: 1.3145 - val_dynamic_f1: 0.4187 - val_loss: 1.4312 - learning_rate: 1.2500e-04\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0001250000059371814.\n",
      "Epoch 35/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dynamic_f1: 0.5049 - loss: 1.3095\n",
      "Epoch 35: saving model to /home/shjee/projects/ecg1d/model/DWT_model_4_leads_lr0.0001_e35_valf10.42.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 68ms/step - dynamic_f1: 0.5049 - loss: 1.3095 - val_dynamic_f1: 0.4243 - val_loss: 1.4307 - learning_rate: 1.2500e-04\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.0001250000059371814.\n",
      "Epoch 36/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dynamic_f1: 0.5085 - loss: 1.3058\n",
      "Epoch 36: saving model to /home/shjee/projects/ecg1d/model/DWT_model_4_leads_lr0.0001_e36_valf10.42.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 68ms/step - dynamic_f1: 0.5085 - loss: 1.3058 - val_dynamic_f1: 0.4239 - val_loss: 1.4246 - learning_rate: 1.2500e-04\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0001250000059371814.\n",
      "Epoch 37/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dynamic_f1: 0.5147 - loss: 1.3011\n",
      "Epoch 37: saving model to /home/shjee/projects/ecg1d/model/DWT_model_4_leads_lr0.0001_e37_valf10.42.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - dynamic_f1: 0.5147 - loss: 1.3011 - val_dynamic_f1: 0.4167 - val_loss: 1.4454 - learning_rate: 1.2500e-04\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0001250000059371814.\n",
      "Epoch 38/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dynamic_f1: 0.5154 - loss: 1.2984\n",
      "Epoch 38: saving model to /home/shjee/projects/ecg1d/model/DWT_model_4_leads_lr0.0001_e38_valf10.42.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 68ms/step - dynamic_f1: 0.5154 - loss: 1.2984 - val_dynamic_f1: 0.4224 - val_loss: 1.4094 - learning_rate: 1.2500e-04\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0001250000059371814.\n",
      "Epoch 39/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - dynamic_f1: 0.5209 - loss: 1.2948\n",
      "Epoch 39: saving model to /home/shjee/projects/ecg1d/model/DWT_model_4_leads_lr0.0001_e39_valf10.43.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 68ms/step - dynamic_f1: 0.5209 - loss: 1.2948 - val_dynamic_f1: 0.4268 - val_loss: 1.4377 - learning_rate: 1.2500e-04\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.0001250000059371814.\n",
      "Epoch 40/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dynamic_f1: 0.5216 - loss: 1.2935\n",
      "Epoch 40: saving model to /home/shjee/projects/ecg1d/model/DWT_model_4_leads_lr0.0001_e40_valf10.42.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - dynamic_f1: 0.5216 - loss: 1.2935 - val_dynamic_f1: 0.4226 - val_loss: 1.4168 - learning_rate: 1.2500e-04\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 6.25000029685907e-05.\n",
      "Epoch 41/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dynamic_f1: 0.5276 - loss: 1.2884\n",
      "Epoch 41: saving model to /home/shjee/projects/ecg1d/model/DWT_model_4_leads_lr0.0001_e41_valf10.42.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - dynamic_f1: 0.5277 - loss: 1.2884 - val_dynamic_f1: 0.4228 - val_loss: 1.4343 - learning_rate: 6.2500e-05\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 6.25000029685907e-05.\n",
      "Epoch 42/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dynamic_f1: 0.5330 - loss: 1.2824\n",
      "Epoch 42: saving model to /home/shjee/projects/ecg1d/model/DWT_model_4_leads_lr0.0001_e42_valf10.42.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 68ms/step - dynamic_f1: 0.5330 - loss: 1.2824 - val_dynamic_f1: 0.4235 - val_loss: 1.4412 - learning_rate: 6.2500e-05\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 6.25000029685907e-05.\n",
      "Epoch 43/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dynamic_f1: 0.5355 - loss: 1.2796\n",
      "Epoch 43: saving model to /home/shjee/projects/ecg1d/model/DWT_model_4_leads_lr0.0001_e43_valf10.42.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 68ms/step - dynamic_f1: 0.5356 - loss: 1.2796 - val_dynamic_f1: 0.4182 - val_loss: 1.4396 - learning_rate: 6.2500e-05\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 6.25000029685907e-05.\n",
      "Epoch 44/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dynamic_f1: 0.5373 - loss: 1.2781\n",
      "Epoch 44: saving model to /home/shjee/projects/ecg1d/model/DWT_model_4_leads_lr0.0001_e44_valf10.41.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 69ms/step - dynamic_f1: 0.5373 - loss: 1.2781 - val_dynamic_f1: 0.4127 - val_loss: 1.4343 - learning_rate: 6.2500e-05\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 6.25000029685907e-05.\n",
      "Epoch 45/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dynamic_f1: 0.5387 - loss: 1.2764\n",
      "Epoch 45: saving model to /home/shjee/projects/ecg1d/model/DWT_model_4_leads_lr0.0001_e45_valf10.42.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 68ms/step - dynamic_f1: 0.5387 - loss: 1.2764 - val_dynamic_f1: 0.4221 - val_loss: 1.4218 - learning_rate: 6.2500e-05\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 6.25000029685907e-05.\n",
      "Epoch 46/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dynamic_f1: 0.5405 - loss: 1.2734\n",
      "Epoch 46: saving model to /home/shjee/projects/ecg1d/model/DWT_model_4_leads_lr0.0001_e46_valf10.42.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - dynamic_f1: 0.5406 - loss: 1.2734 - val_dynamic_f1: 0.4196 - val_loss: 1.4447 - learning_rate: 6.2500e-05\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 6.25000029685907e-05.\n",
      "Epoch 47/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - dynamic_f1: 0.5428 - loss: 1.2703\n",
      "Epoch 47: saving model to /home/shjee/projects/ecg1d/model/DWT_model_4_leads_lr0.0001_e47_valf10.41.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - dynamic_f1: 0.5428 - loss: 1.2703 - val_dynamic_f1: 0.4147 - val_loss: 1.4262 - learning_rate: 6.2500e-05\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 6.25000029685907e-05.\n",
      "Epoch 48/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dynamic_f1: 0.5468 - loss: 1.2663\n",
      "Epoch 48: saving model to /home/shjee/projects/ecg1d/model/DWT_model_4_leads_lr0.0001_e48_valf10.42.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 68ms/step - dynamic_f1: 0.5469 - loss: 1.2663 - val_dynamic_f1: 0.4212 - val_loss: 1.4227 - learning_rate: 6.2500e-05\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 6.25000029685907e-05.\n",
      "Epoch 49/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dynamic_f1: 0.5502 - loss: 1.2628\n",
      "Epoch 49: saving model to /home/shjee/projects/ecg1d/model/DWT_model_4_leads_lr0.0001_e49_valf10.42.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - dynamic_f1: 0.5502 - loss: 1.2628 - val_dynamic_f1: 0.4210 - val_loss: 1.4311 - learning_rate: 6.2500e-05\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 6.25000029685907e-05.\n",
      "Epoch 50/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - dynamic_f1: 0.5532 - loss: 1.2613\n",
      "Epoch 50: saving model to /home/shjee/projects/ecg1d/model/DWT_model_4_leads_lr0.0001_e50_valf10.42.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - dynamic_f1: 0.5532 - loss: 1.2613 - val_dynamic_f1: 0.4225 - val_loss: 1.4313 - learning_rate: 6.2500e-05\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 3.125000148429535e-05.\n",
      "Epoch 51/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dynamic_f1: 0.5556 - loss: 1.2594\n",
      "Epoch 51: saving model to /home/shjee/projects/ecg1d/model/DWT_model_4_leads_lr0.0001_e51_valf10.42.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 68ms/step - dynamic_f1: 0.5556 - loss: 1.2594 - val_dynamic_f1: 0.4211 - val_loss: 1.4353 - learning_rate: 3.1250e-05\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 3.125000148429535e-05.\n",
      "Epoch 52/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dynamic_f1: 0.5576 - loss: 1.2579\n",
      "Epoch 52: saving model to /home/shjee/projects/ecg1d/model/DWT_model_4_leads_lr0.0001_e52_valf10.42.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 70ms/step - dynamic_f1: 0.5576 - loss: 1.2579 - val_dynamic_f1: 0.4215 - val_loss: 1.4328 - learning_rate: 3.1250e-05\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 3.125000148429535e-05.\n",
      "Epoch 53/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dynamic_f1: 0.5582 - loss: 1.2577\n",
      "Epoch 53: saving model to /home/shjee/projects/ecg1d/model/DWT_model_4_leads_lr0.0001_e53_valf10.42.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 69ms/step - dynamic_f1: 0.5582 - loss: 1.2577 - val_dynamic_f1: 0.4209 - val_loss: 1.4360 - learning_rate: 3.1250e-05\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 3.125000148429535e-05.\n",
      "Epoch 54/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - dynamic_f1: 0.5573 - loss: 1.2584\n",
      "Epoch 54: saving model to /home/shjee/projects/ecg1d/model/DWT_model_4_leads_lr0.0001_e54_valf10.42.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 66ms/step - dynamic_f1: 0.5574 - loss: 1.2584 - val_dynamic_f1: 0.4207 - val_loss: 1.4274 - learning_rate: 3.1250e-05\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 3.125000148429535e-05.\n",
      "Epoch 55/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dynamic_f1: 0.5578 - loss: 1.2575\n",
      "Epoch 55: saving model to /home/shjee/projects/ecg1d/model/DWT_model_4_leads_lr0.0001_e55_valf10.42.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - dynamic_f1: 0.5578 - loss: 1.2575 - val_dynamic_f1: 0.4192 - val_loss: 1.4263 - learning_rate: 3.1250e-05\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 3.125000148429535e-05.\n",
      "Epoch 56/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dynamic_f1: 0.5600 - loss: 1.2565\n",
      "Epoch 56: saving model to /home/shjee/projects/ecg1d/model/DWT_model_4_leads_lr0.0001_e56_valf10.42.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 68ms/step - dynamic_f1: 0.5600 - loss: 1.2565 - val_dynamic_f1: 0.4247 - val_loss: 1.4308 - learning_rate: 3.1250e-05\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 3.125000148429535e-05.\n",
      "Epoch 57/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dynamic_f1: 0.5618 - loss: 1.2559\n",
      "Epoch 57: saving model to /home/shjee/projects/ecg1d/model/DWT_model_4_leads_lr0.0001_e57_valf10.42.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - dynamic_f1: 0.5618 - loss: 1.2559 - val_dynamic_f1: 0.4151 - val_loss: 1.4343 - learning_rate: 3.1250e-05\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 3.125000148429535e-05.\n",
      "Epoch 58/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dynamic_f1: 0.5646 - loss: 1.2534\n",
      "Epoch 58: saving model to /home/shjee/projects/ecg1d/model/DWT_model_4_leads_lr0.0001_e58_valf10.42.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - dynamic_f1: 0.5646 - loss: 1.2534 - val_dynamic_f1: 0.4178 - val_loss: 1.4280 - learning_rate: 3.1250e-05\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 3.125000148429535e-05.\n",
      "Epoch 59/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dynamic_f1: 0.5688 - loss: 1.2509\n",
      "Epoch 59: saving model to /home/shjee/projects/ecg1d/model/DWT_model_4_leads_lr0.0001_e59_valf10.42.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - dynamic_f1: 0.5688 - loss: 1.2509 - val_dynamic_f1: 0.4180 - val_loss: 1.4317 - learning_rate: 3.1250e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing with Pan-Tompkins + interpolate + standardize:   0%|          | 0/61707 [00:00<?, ?it/s]/home/shjee/projects/ecg1d/team_code.py:766: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  lead_series = lead_series.interpolate(method='linear').fillna(method='bfill').fillna(method='ffill')\n",
      "Preprocessing with Pan-Tompkins + interpolate + standardize: 100%|██████████| 61707/61707 [00:32<00:00, 1881.79it/s]\n",
      "Preprocessing with Pan-Tompkins + interpolate + standardize: 100%|██████████| 7718/7718 [00:03<00:00, 2153.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtering complete\n",
      "Train Start...\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-11 14:55:56.705594: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'input_convert_reduce_fusion_19', 8 bytes spill stores, 8 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_convert_reduce_fusion_6', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - dynamic_f1: 0.1253 - loss: 2.5186\n",
      "Epoch 1: saving model to /home/shjee/projects/ecg1d/model/PT_model_3_leads_lr0.0001_e01_valf10.09.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 87ms/step - dynamic_f1: 0.1253 - loss: 2.5174 - val_dynamic_f1: 0.0904 - val_loss: 1.8794 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 2/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dynamic_f1: 0.1130 - loss: 1.9302\n",
      "Epoch 2: saving model to /home/shjee/projects/ecg1d/model/PT_model_3_leads_lr0.0001_e02_valf10.11.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - dynamic_f1: 0.1130 - loss: 1.9301 - val_dynamic_f1: 0.1123 - val_loss: 3.4128 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 3/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - dynamic_f1: 0.1012 - loss: 1.8943\n",
      "Epoch 3: saving model to /home/shjee/projects/ecg1d/model/PT_model_3_leads_lr0.0001_e03_valf10.09.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 68ms/step - dynamic_f1: 0.1012 - loss: 1.8942 - val_dynamic_f1: 0.0917 - val_loss: 1.8395 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 4/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dynamic_f1: 0.0975 - loss: 1.8731\n",
      "Epoch 4: saving model to /home/shjee/projects/ecg1d/model/PT_model_3_leads_lr0.0001_e04_valf10.10.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 67ms/step - dynamic_f1: 0.0975 - loss: 1.8731 - val_dynamic_f1: 0.0969 - val_loss: 1.8302 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 5/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - dynamic_f1: 0.0965 - loss: 1.8701\n",
      "Epoch 5: saving model to /home/shjee/projects/ecg1d/model/PT_model_3_leads_lr0.0001_e05_valf10.10.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 69ms/step - dynamic_f1: 0.0965 - loss: 1.8701 - val_dynamic_f1: 0.0968 - val_loss: 1.8240 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 6/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - dynamic_f1: 0.0969 - loss: 1.8708\n",
      "Epoch 6: saving model to /home/shjee/projects/ecg1d/model/PT_model_3_leads_lr0.0001_e06_valf10.09.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - dynamic_f1: 0.0969 - loss: 1.8708 - val_dynamic_f1: 0.0948 - val_loss: 1.8218 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 7/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - dynamic_f1: 0.0968 - loss: 1.8699\n",
      "Epoch 7: saving model to /home/shjee/projects/ecg1d/model/PT_model_3_leads_lr0.0001_e07_valf10.10.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - dynamic_f1: 0.0968 - loss: 1.8699 - val_dynamic_f1: 0.1040 - val_loss: 1.8133 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 8/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - dynamic_f1: 0.0966 - loss: 1.8722\n",
      "Epoch 8: saving model to /home/shjee/projects/ecg1d/model/PT_model_3_leads_lr0.0001_e08_valf10.09.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - dynamic_f1: 0.0966 - loss: 1.8722 - val_dynamic_f1: 0.0931 - val_loss: 1.8536 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 9/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dynamic_f1: 0.0984 - loss: 1.8703\n",
      "Epoch 9: saving model to /home/shjee/projects/ecg1d/model/PT_model_3_leads_lr0.0001_e09_valf10.09.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 68ms/step - dynamic_f1: 0.0984 - loss: 1.8703 - val_dynamic_f1: 0.0939 - val_loss: 1.8147 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 10/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - dynamic_f1: 0.0993 - loss: 1.8703\n",
      "Epoch 10: saving model to /home/shjee/projects/ecg1d/model/PT_model_3_leads_lr0.0001_e10_valf10.10.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - dynamic_f1: 0.0993 - loss: 1.8703 - val_dynamic_f1: 0.1033 - val_loss: 1.8224 - learning_rate: 0.0010\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.0005000000237487257.\n",
      "Epoch 11/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - dynamic_f1: 0.1047 - loss: 1.8588\n",
      "Epoch 11: saving model to /home/shjee/projects/ecg1d/model/PT_model_3_leads_lr0.0001_e11_valf10.12.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - dynamic_f1: 0.1047 - loss: 1.8588 - val_dynamic_f1: 0.1185 - val_loss: 2.0643 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.0005000000237487257.\n",
      "Epoch 12/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - dynamic_f1: 0.1054 - loss: 1.8591\n",
      "Epoch 12: saving model to /home/shjee/projects/ecg1d/model/PT_model_3_leads_lr0.0001_e12_valf10.10.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - dynamic_f1: 0.1054 - loss: 1.8591 - val_dynamic_f1: 0.1006 - val_loss: 1.7834 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.0005000000237487257.\n",
      "Epoch 13/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - dynamic_f1: 0.1059 - loss: 1.8594\n",
      "Epoch 13: saving model to /home/shjee/projects/ecg1d/model/PT_model_3_leads_lr0.0001_e13_valf10.11.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 68ms/step - dynamic_f1: 0.1059 - loss: 1.8594 - val_dynamic_f1: 0.1143 - val_loss: 1.8026 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.0005000000237487257.\n",
      "Epoch 14/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - dynamic_f1: 0.1070 - loss: 1.8576\n",
      "Epoch 14: saving model to /home/shjee/projects/ecg1d/model/PT_model_3_leads_lr0.0001_e14_valf10.10.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - dynamic_f1: 0.1070 - loss: 1.8576 - val_dynamic_f1: 0.1019 - val_loss: 1.7762 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0005000000237487257.\n",
      "Epoch 15/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - dynamic_f1: 0.1077 - loss: 1.8525\n",
      "Epoch 15: saving model to /home/shjee/projects/ecg1d/model/PT_model_3_leads_lr0.0001_e15_valf10.10.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 68ms/step - dynamic_f1: 0.1077 - loss: 1.8525 - val_dynamic_f1: 0.0993 - val_loss: 1.7857 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.0005000000237487257.\n",
      "Epoch 16/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dynamic_f1: 0.1078 - loss: 1.8471\n",
      "Epoch 16: saving model to /home/shjee/projects/ecg1d/model/PT_model_3_leads_lr0.0001_e16_valf10.10.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - dynamic_f1: 0.1079 - loss: 1.8471 - val_dynamic_f1: 0.1049 - val_loss: 1.7838 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0005000000237487257.\n",
      "Epoch 17/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dynamic_f1: 0.1071 - loss: 1.8447\n",
      "Epoch 17: saving model to /home/shjee/projects/ecg1d/model/PT_model_3_leads_lr0.0001_e17_valf10.11.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 68ms/step - dynamic_f1: 0.1071 - loss: 1.8447 - val_dynamic_f1: 0.1058 - val_loss: 1.7842 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.0005000000237487257.\n",
      "Epoch 18/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - dynamic_f1: 0.1077 - loss: 1.8427\n",
      "Epoch 18: saving model to /home/shjee/projects/ecg1d/model/PT_model_3_leads_lr0.0001_e18_valf10.11.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - dynamic_f1: 0.1077 - loss: 1.8426 - val_dynamic_f1: 0.1132 - val_loss: 1.7526 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.0005000000237487257.\n",
      "Epoch 19/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - dynamic_f1: 0.1082 - loss: 1.8387\n",
      "Epoch 19: saving model to /home/shjee/projects/ecg1d/model/PT_model_3_leads_lr0.0001_e19_valf10.12.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 68ms/step - dynamic_f1: 0.1082 - loss: 1.8387 - val_dynamic_f1: 0.1154 - val_loss: 1.7788 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.0005000000237487257.\n",
      "Epoch 20/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - dynamic_f1: 0.1095 - loss: 1.8411\n",
      "Epoch 20: saving model to /home/shjee/projects/ecg1d/model/PT_model_3_leads_lr0.0001_e20_valf10.12.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 70ms/step - dynamic_f1: 0.1095 - loss: 1.8411 - val_dynamic_f1: 0.1177 - val_loss: 1.8024 - learning_rate: 5.0000e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0002500000118743628.\n",
      "Epoch 21/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - dynamic_f1: 0.1098 - loss: 1.8315\n",
      "Epoch 21: saving model to /home/shjee/projects/ecg1d/model/PT_model_3_leads_lr0.0001_e21_valf10.11.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - dynamic_f1: 0.1098 - loss: 1.8314 - val_dynamic_f1: 0.1057 - val_loss: 1.7566 - learning_rate: 2.5000e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.0002500000118743628.\n",
      "Epoch 22/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - dynamic_f1: 0.1107 - loss: 1.8311\n",
      "Epoch 22: saving model to /home/shjee/projects/ecg1d/model/PT_model_3_leads_lr0.0001_e22_valf10.12.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - dynamic_f1: 0.1108 - loss: 1.8310 - val_dynamic_f1: 0.1154 - val_loss: 1.7769 - learning_rate: 2.5000e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.0002500000118743628.\n",
      "Epoch 23/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - dynamic_f1: 0.1113 - loss: 1.8296\n",
      "Epoch 23: saving model to /home/shjee/projects/ecg1d/model/PT_model_3_leads_lr0.0001_e23_valf10.12.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - dynamic_f1: 0.1113 - loss: 1.8295 - val_dynamic_f1: 0.1152 - val_loss: 1.7744 - learning_rate: 2.5000e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0002500000118743628.\n",
      "Epoch 24/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - dynamic_f1: 0.1111 - loss: 1.8279\n",
      "Epoch 24: saving model to /home/shjee/projects/ecg1d/model/PT_model_3_leads_lr0.0001_e24_valf10.12.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - dynamic_f1: 0.1111 - loss: 1.8278 - val_dynamic_f1: 0.1168 - val_loss: 1.7811 - learning_rate: 2.5000e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.0002500000118743628.\n",
      "Epoch 25/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - dynamic_f1: 0.1117 - loss: 1.8251\n",
      "Epoch 25: saving model to /home/shjee/projects/ecg1d/model/PT_model_3_leads_lr0.0001_e25_valf10.12.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - dynamic_f1: 0.1117 - loss: 1.8251 - val_dynamic_f1: 0.1158 - val_loss: 1.7807 - learning_rate: 2.5000e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0002500000118743628.\n",
      "Epoch 26/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dynamic_f1: 0.1114 - loss: 1.8245\n",
      "Epoch 26: saving model to /home/shjee/projects/ecg1d/model/PT_model_3_leads_lr0.0001_e26_valf10.12.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 68ms/step - dynamic_f1: 0.1114 - loss: 1.8244 - val_dynamic_f1: 0.1163 - val_loss: 1.7799 - learning_rate: 2.5000e-04\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.0002500000118743628.\n",
      "Epoch 27/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dynamic_f1: 0.1135 - loss: 1.8249\n",
      "Epoch 27: saving model to /home/shjee/projects/ecg1d/model/PT_model_3_leads_lr0.0001_e27_valf10.11.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - dynamic_f1: 0.1135 - loss: 1.8249 - val_dynamic_f1: 0.1137 - val_loss: 1.7750 - learning_rate: 2.5000e-04\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.0002500000118743628.\n",
      "Epoch 28/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dynamic_f1: 0.1146 - loss: 1.8208\n",
      "Epoch 28: saving model to /home/shjee/projects/ecg1d/model/PT_model_3_leads_lr0.0001_e28_valf10.12.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - dynamic_f1: 0.1146 - loss: 1.8207 - val_dynamic_f1: 0.1178 - val_loss: 1.7757 - learning_rate: 2.5000e-04\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.0002500000118743628.\n",
      "Epoch 29/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dynamic_f1: 0.1166 - loss: 1.8243\n",
      "Epoch 29: saving model to /home/shjee/projects/ecg1d/model/PT_model_3_leads_lr0.0001_e29_valf10.12.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 68ms/step - dynamic_f1: 0.1167 - loss: 1.8243 - val_dynamic_f1: 0.1151 - val_loss: 1.7651 - learning_rate: 2.5000e-04\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0002500000118743628.\n",
      "Epoch 30/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dynamic_f1: 0.1167 - loss: 1.8205\n",
      "Epoch 30: saving model to /home/shjee/projects/ecg1d/model/PT_model_3_leads_lr0.0001_e30_valf10.12.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 68ms/step - dynamic_f1: 0.1167 - loss: 1.8205 - val_dynamic_f1: 0.1214 - val_loss: 1.7623 - learning_rate: 2.5000e-04\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.0001250000059371814.\n",
      "Epoch 31/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dynamic_f1: 0.1189 - loss: 1.8183\n",
      "Epoch 31: saving model to /home/shjee/projects/ecg1d/model/PT_model_3_leads_lr0.0001_e31_valf10.12.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 68ms/step - dynamic_f1: 0.1189 - loss: 1.8183 - val_dynamic_f1: 0.1183 - val_loss: 1.7584 - learning_rate: 1.2500e-04\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.0001250000059371814.\n",
      "Epoch 32/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dynamic_f1: 0.1197 - loss: 1.8167\n",
      "Epoch 32: saving model to /home/shjee/projects/ecg1d/model/PT_model_3_leads_lr0.0001_e32_valf10.12.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 69ms/step - dynamic_f1: 0.1197 - loss: 1.8167 - val_dynamic_f1: 0.1198 - val_loss: 1.7628 - learning_rate: 1.2500e-04\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.0001250000059371814.\n",
      "Epoch 33/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - dynamic_f1: 0.1199 - loss: 1.8213\n",
      "Epoch 33: saving model to /home/shjee/projects/ecg1d/model/PT_model_3_leads_lr0.0001_e33_valf10.12.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - dynamic_f1: 0.1199 - loss: 1.8212 - val_dynamic_f1: 0.1211 - val_loss: 1.7616 - learning_rate: 1.2500e-04\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.0001250000059371814.\n",
      "Epoch 34/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - dynamic_f1: 0.1197 - loss: 1.8208\n",
      "Epoch 34: saving model to /home/shjee/projects/ecg1d/model/PT_model_3_leads_lr0.0001_e34_valf10.12.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 68ms/step - dynamic_f1: 0.1197 - loss: 1.8207 - val_dynamic_f1: 0.1200 - val_loss: 1.7595 - learning_rate: 1.2500e-04\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0001250000059371814.\n",
      "Epoch 35/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - dynamic_f1: 0.1196 - loss: 1.8196\n",
      "Epoch 35: saving model to /home/shjee/projects/ecg1d/model/PT_model_3_leads_lr0.0001_e35_valf10.12.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - dynamic_f1: 0.1196 - loss: 1.8195 - val_dynamic_f1: 0.1231 - val_loss: 1.7549 - learning_rate: 1.2500e-04\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.0001250000059371814.\n",
      "Epoch 36/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - dynamic_f1: 0.1198 - loss: 1.8206\n",
      "Epoch 36: saving model to /home/shjee/projects/ecg1d/model/PT_model_3_leads_lr0.0001_e36_valf10.12.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - dynamic_f1: 0.1198 - loss: 1.8206 - val_dynamic_f1: 0.1190 - val_loss: 1.7543 - learning_rate: 1.2500e-04\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0001250000059371814.\n",
      "Epoch 37/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - dynamic_f1: 0.1190 - loss: 1.8188\n",
      "Epoch 37: saving model to /home/shjee/projects/ecg1d/model/PT_model_3_leads_lr0.0001_e37_valf10.12.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - dynamic_f1: 0.1190 - loss: 1.8188 - val_dynamic_f1: 0.1167 - val_loss: 1.7764 - learning_rate: 1.2500e-04\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0001250000059371814.\n",
      "Epoch 38/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dynamic_f1: 0.1200 - loss: 1.8173\n",
      "Epoch 38: saving model to /home/shjee/projects/ecg1d/model/PT_model_3_leads_lr0.0001_e38_valf10.12.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - dynamic_f1: 0.1200 - loss: 1.8173 - val_dynamic_f1: 0.1201 - val_loss: 1.7419 - learning_rate: 1.2500e-04\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0001250000059371814.\n",
      "Epoch 39/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dynamic_f1: 0.1207 - loss: 1.8189\n",
      "Epoch 39: saving model to /home/shjee/projects/ecg1d/model/PT_model_3_leads_lr0.0001_e39_valf10.12.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - dynamic_f1: 0.1207 - loss: 1.8189 - val_dynamic_f1: 0.1224 - val_loss: 1.7751 - learning_rate: 1.2500e-04\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.0001250000059371814.\n",
      "Epoch 40/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - dynamic_f1: 0.1201 - loss: 1.8173\n",
      "Epoch 40: saving model to /home/shjee/projects/ecg1d/model/PT_model_3_leads_lr0.0001_e40_valf10.11.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 69ms/step - dynamic_f1: 0.1201 - loss: 1.8173 - val_dynamic_f1: 0.1085 - val_loss: 1.7528 - learning_rate: 1.2500e-04\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 6.25000029685907e-05.\n",
      "Epoch 41/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - dynamic_f1: 0.1207 - loss: 1.8161\n",
      "Epoch 41: saving model to /home/shjee/projects/ecg1d/model/PT_model_3_leads_lr0.0001_e41_valf10.11.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - dynamic_f1: 0.1207 - loss: 1.8161 - val_dynamic_f1: 0.1086 - val_loss: 1.7650 - learning_rate: 6.2500e-05\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 6.25000029685907e-05.\n",
      "Epoch 42/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - dynamic_f1: 0.1216 - loss: 1.8139\n",
      "Epoch 42: saving model to /home/shjee/projects/ecg1d/model/PT_model_3_leads_lr0.0001_e42_valf10.11.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - dynamic_f1: 0.1216 - loss: 1.8139 - val_dynamic_f1: 0.1098 - val_loss: 1.7757 - learning_rate: 6.2500e-05\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 6.25000029685907e-05.\n",
      "Epoch 43/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - dynamic_f1: 0.1212 - loss: 1.8137\n",
      "Epoch 43: saving model to /home/shjee/projects/ecg1d/model/PT_model_3_leads_lr0.0001_e43_valf10.11.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 68ms/step - dynamic_f1: 0.1212 - loss: 1.8136 - val_dynamic_f1: 0.1100 - val_loss: 1.7667 - learning_rate: 6.2500e-05\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 6.25000029685907e-05.\n",
      "Epoch 44/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dynamic_f1: 0.1206 - loss: 1.8112\n",
      "Epoch 44: saving model to /home/shjee/projects/ecg1d/model/PT_model_3_leads_lr0.0001_e44_valf10.11.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 69ms/step - dynamic_f1: 0.1206 - loss: 1.8112 - val_dynamic_f1: 0.1134 - val_loss: 1.7493 - learning_rate: 6.2500e-05\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 6.25000029685907e-05.\n",
      "Epoch 45/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dynamic_f1: 0.1205 - loss: 1.8107\n",
      "Epoch 45: saving model to /home/shjee/projects/ecg1d/model/PT_model_3_leads_lr0.0001_e45_valf10.11.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 67ms/step - dynamic_f1: 0.1205 - loss: 1.8106 - val_dynamic_f1: 0.1121 - val_loss: 1.7506 - learning_rate: 6.2500e-05\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 6.25000029685907e-05.\n",
      "Epoch 46/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dynamic_f1: 0.1207 - loss: 1.8111\n",
      "Epoch 46: saving model to /home/shjee/projects/ecg1d/model/PT_model_3_leads_lr0.0001_e46_valf10.12.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 68ms/step - dynamic_f1: 0.1207 - loss: 1.8111 - val_dynamic_f1: 0.1158 - val_loss: 1.7593 - learning_rate: 6.2500e-05\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 6.25000029685907e-05.\n",
      "Epoch 47/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - dynamic_f1: 0.1206 - loss: 1.8062\n",
      "Epoch 47: saving model to /home/shjee/projects/ecg1d/model/PT_model_3_leads_lr0.0001_e47_valf10.11.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - dynamic_f1: 0.1206 - loss: 1.8062 - val_dynamic_f1: 0.1121 - val_loss: 1.7489 - learning_rate: 6.2500e-05\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 6.25000029685907e-05.\n",
      "Epoch 48/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - dynamic_f1: 0.1207 - loss: 1.8080\n",
      "Epoch 48: saving model to /home/shjee/projects/ecg1d/model/PT_model_3_leads_lr0.0001_e48_valf10.12.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - dynamic_f1: 0.1207 - loss: 1.8080 - val_dynamic_f1: 0.1234 - val_loss: 1.7445 - learning_rate: 6.2500e-05\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 6.25000029685907e-05.\n",
      "Epoch 49/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - dynamic_f1: 0.1209 - loss: 1.8070\n",
      "Epoch 49: saving model to /home/shjee/projects/ecg1d/model/PT_model_3_leads_lr0.0001_e49_valf10.12.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - dynamic_f1: 0.1209 - loss: 1.8069 - val_dynamic_f1: 0.1238 - val_loss: 1.7557 - learning_rate: 6.2500e-05\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 6.25000029685907e-05.\n",
      "Epoch 50/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - dynamic_f1: 0.1209 - loss: 1.8063\n",
      "Epoch 50: saving model to /home/shjee/projects/ecg1d/model/PT_model_3_leads_lr0.0001_e50_valf10.12.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - dynamic_f1: 0.1209 - loss: 1.8063 - val_dynamic_f1: 0.1214 - val_loss: 1.7581 - learning_rate: 6.2500e-05\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 3.125000148429535e-05.\n",
      "Epoch 51/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - dynamic_f1: 0.1240 - loss: 1.8065\n",
      "Epoch 51: saving model to /home/shjee/projects/ecg1d/model/PT_model_3_leads_lr0.0001_e51_valf10.12.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - dynamic_f1: 0.1240 - loss: 1.8064 - val_dynamic_f1: 0.1222 - val_loss: 1.7654 - learning_rate: 3.1250e-05\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 3.125000148429535e-05.\n",
      "Epoch 52/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - dynamic_f1: 0.1243 - loss: 1.8036\n",
      "Epoch 52: saving model to /home/shjee/projects/ecg1d/model/PT_model_3_leads_lr0.0001_e52_valf10.12.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 70ms/step - dynamic_f1: 0.1243 - loss: 1.8036 - val_dynamic_f1: 0.1247 - val_loss: 1.7622 - learning_rate: 3.1250e-05\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 3.125000148429535e-05.\n",
      "Epoch 53/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - dynamic_f1: 0.1247 - loss: 1.8023\n",
      "Epoch 53: saving model to /home/shjee/projects/ecg1d/model/PT_model_3_leads_lr0.0001_e53_valf10.12.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - dynamic_f1: 0.1247 - loss: 1.8023 - val_dynamic_f1: 0.1241 - val_loss: 1.7563 - learning_rate: 3.1250e-05\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 3.125000148429535e-05.\n",
      "Epoch 54/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - dynamic_f1: 0.1242 - loss: 1.8011\n",
      "Epoch 54: saving model to /home/shjee/projects/ecg1d/model/PT_model_3_leads_lr0.0001_e54_valf10.12.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 70ms/step - dynamic_f1: 0.1242 - loss: 1.8011 - val_dynamic_f1: 0.1247 - val_loss: 1.7539 - learning_rate: 3.1250e-05\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 3.125000148429535e-05.\n",
      "Epoch 55/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - dynamic_f1: 0.1252 - loss: 1.8012\n",
      "Epoch 55: saving model to /home/shjee/projects/ecg1d/model/PT_model_3_leads_lr0.0001_e55_valf10.12.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - dynamic_f1: 0.1252 - loss: 1.8012 - val_dynamic_f1: 0.1239 - val_loss: 1.7561 - learning_rate: 3.1250e-05\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 3.125000148429535e-05.\n",
      "Epoch 56/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - dynamic_f1: 0.1256 - loss: 1.8021\n",
      "Epoch 56: saving model to /home/shjee/projects/ecg1d/model/PT_model_3_leads_lr0.0001_e56_valf10.13.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - dynamic_f1: 0.1256 - loss: 1.8021 - val_dynamic_f1: 0.1252 - val_loss: 1.7595 - learning_rate: 3.1250e-05\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 3.125000148429535e-05.\n",
      "Epoch 57/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - dynamic_f1: 0.1246 - loss: 1.8036\n",
      "Epoch 57: saving model to /home/shjee/projects/ecg1d/model/PT_model_3_leads_lr0.0001_e57_valf10.13.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 71ms/step - dynamic_f1: 0.1246 - loss: 1.8036 - val_dynamic_f1: 0.1255 - val_loss: 1.7547 - learning_rate: 3.1250e-05\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 3.125000148429535e-05.\n",
      "Epoch 58/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - dynamic_f1: 0.1252 - loss: 1.8018\n",
      "Epoch 58: saving model to /home/shjee/projects/ecg1d/model/PT_model_3_leads_lr0.0001_e58_valf10.13.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 68ms/step - dynamic_f1: 0.1252 - loss: 1.8018 - val_dynamic_f1: 0.1250 - val_loss: 1.7555 - learning_rate: 3.1250e-05\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 3.125000148429535e-05.\n",
      "Epoch 59/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - dynamic_f1: 0.1254 - loss: 1.8015\n",
      "Epoch 59: saving model to /home/shjee/projects/ecg1d/model/PT_model_3_leads_lr0.0001_e59_valf10.13.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - dynamic_f1: 0.1254 - loss: 1.8015 - val_dynamic_f1: 0.1258 - val_loss: 1.7553 - learning_rate: 3.1250e-05\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 3.125000148429535e-05.\n",
      "Epoch 60/60\n",
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - dynamic_f1: 0.1242 - loss: 1.8004\n",
      "Epoch 60: saving model to /home/shjee/projects/ecg1d/model/PT_model_3_leads_lr0.0001_e60_valf10.12.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 70ms/step - dynamic_f1: 0.1242 - loss: 1.8004 - val_dynamic_f1: 0.1243 - val_loss: 1.7564 - learning_rate: 3.1250e-05\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from team_code import load_data, load_data_2, train_model_2, X_rawecg, X_dwt, X_pan_tomkins, train_model_3\n",
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "with tf.device('/device:GPU:1'):\n",
    "    policy = mixed_precision.Policy('mixed_float16')  # FP16 연산 적용\n",
    "    mixed_precision.set_global_policy(policy)\n",
    "\n",
    "    filters = ['Raw', 'DWT', 'PT']\n",
    "    lr =  0.0001\n",
    "\n",
    "    for i, f in enumerate(filters) :\n",
    "        for leads in lead_sets:\n",
    "            num_leads = len(leads)\n",
    "\n",
    "            if (i, num_leads) not in {(1, 3)}:\n",
    "                continue\n",
    "\n",
    "\n",
    "            '''전처리 과정 함수'''\n",
    "            if i ==  0 :\n",
    "                X_train_all_filtered = X_rawecg(X_train_all, num_leads)\n",
    "                X_val_all_filtered = X_rawecg(X_val_all, num_leads)\n",
    "                print(\"filtering complete\")\n",
    "\n",
    "            if i ==  1 :\n",
    "                X_train_all_filtered = X_dwt(X_train_all, num_leads)\n",
    "                X_val_all_filtered = X_dwt(X_val_all, num_leads)\n",
    "                print(\"filtering complete\")\n",
    "\n",
    "            if i ==  2 :\n",
    "                X_train_all_filtered = X_pan_tomkins(X_train_all, num_leads)\n",
    "                X_val_all_filtered = X_pan_tomkins(X_val_all, num_leads)\n",
    "                print(\"filtering complete\")\n",
    "\n",
    "            model_name = f\"{f}_model_{num_leads}_leads_lr{lr}\"\n",
    "\n",
    "            train_model_3(X_train_all_filtered, y_train_all, X_val_all_filtered, y_val_all, num_leads, batch_size, lr,  epochs, signal_len, model_name, model_directory, i)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Test, validation 데이터 저장'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Test, validation 데이터 저장'''\n",
    "\n",
    "# np.savez('ecg_test_data.npz', X=X_test_all, y=y_test_all)\n",
    "# np.savez('ecg_val_data.npz', X=X_val_all, y=y_val_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
